{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# import yfinance as yf\n",
    "from sklearn import covariance, cluster\n",
    "from json import loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Total', 'Exxon', 'Chevron', 'ConocoPhillips', 'Valero Energy',\n",
       "       'Microsoft', 'IBM', 'Time Warner', 'Comcast', 'Cablevision',\n",
       "       'Yahoo', 'Dell', 'HP', 'Amazon', 'Toyota', 'Canon', 'Mitsubishi',\n",
       "       'Sony', 'Ford', 'Honda', 'Navistar', 'Northrop Grumman', 'Boeing',\n",
       "       'Coca Cola', '3M', 'Mc Donalds', 'Pepsi', 'Kraft Foods', 'Kellogg',\n",
       "       'Unilever', 'Marriott', 'Procter Gamble', 'Colgate-Palmolive',\n",
       "       'General Electrics', 'Wells Fargo', 'JPMorgan Chase', 'AIG',\n",
       "       'American express', 'Bank of America', 'Goldman Sachs', 'Apple',\n",
       "       'SAP', 'Cisco', 'Texas instruments', 'Xerox', 'Lookheed Martin',\n",
       "       'Wal-Mart', 'Walgreen', 'Home Depot', 'GlaxoSmithKline', 'Pfizer',\n",
       "       'Sanofi-Aventis', 'Novartis', 'Kimberly-Clark', 'Ryder',\n",
       "       'General Dynamics', 'Raytheon', 'CVS', 'Caterpillar',\n",
       "       'DuPont de Nemours'], dtype='<U17')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input file containing company symbols \n",
    "input_file = '../aiwp-data/company_symbol_mapping.json'\n",
    "\n",
    "# Load the company symbol map\n",
    "with open(input_file, 'r') as f:\n",
    "    company_symbols_map = loads(f.read())\n",
    "\n",
    "symbols, names = np.array(list(company_symbols_map.items())).T\n",
    "names\n",
    "# for symbol in symbols[:3]:\n",
    "#     print(symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the historical stock quotes \n",
    "# start_date = datetime.datetime(2003, 1, 1).strftime(\"%Y-%m-%d\")\n",
    "# end_date = datetime.datetime(2023, 9, 26).strftime(\"%Y-%m-%d\")\n",
    "# # downloading task\n",
    "# for symbol in symbols:\n",
    "#     df = yf.download('SPY',start=start_date, end = end_date)\n",
    "#     df.to_csv(f'./stockdata/{symbol}.csv', encoding='utf-8', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-02</th>\n",
       "      <td>88.849998</td>\n",
       "      <td>91.300003</td>\n",
       "      <td>88.540001</td>\n",
       "      <td>91.070000</td>\n",
       "      <td>61.366577</td>\n",
       "      <td>44516300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-03</th>\n",
       "      <td>90.910004</td>\n",
       "      <td>91.379997</td>\n",
       "      <td>90.500000</td>\n",
       "      <td>91.349998</td>\n",
       "      <td>61.555252</td>\n",
       "      <td>32222600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close    Volume\n",
       "Date                                                                       \n",
       "2003-01-02  88.849998  91.300003  88.540001  91.070000  61.366577  44516300\n",
       "2003-01-03  90.910004  91.379997  90.500000  91.349998  61.555252  32222600"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'./stockdata/MSFT.csv', index_col=0, parse_dates=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symbol_sample = symbols[:3]\n",
    "# name_sample = names[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quotes = [pd.read_csv(f'./stockdata/{symbol}.csv', index_col=0, parse_dates=True) for symbol in symbol_sample]\n",
    "quotes = [pd.read_csv(f'./stockdata/{symbol}.csv', index_col=0, parse_dates=True) for symbol in symbols]\n",
    "# quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.float = float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract opening and closing quotes\n",
    "# opening_quotes = np.array([quote['Open'] for quote in quotes]).astype(np.float)\n",
    "# closing_quotes = np.array([quote['Close'] for quote in quotes]).astype(np.float)\n",
    "# # opening_quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute differences between opening and closing quotes \n",
    "# quotes_diff = closing_quotes - opening_quotes\n",
    "# # quotes_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = quotes_diff.copy()\n",
    "# # X.shape     # (3, 5218)\n",
    "# # X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize the data \n",
    "# X = quotes_diff.copy().T\n",
    "# # X.shape     # (5218, 3)\n",
    "# # type(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X /= X.std(axis=0)\n",
    "# # type(X)   # numpy.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a graph model \n",
    "# edge_model = covariance.GraphicalLassoCV()\n",
    "# # edge_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model\n",
    "# with np.errstate(invalid='ignore'):\n",
    "#     edge_model.fit(X)\n",
    "\n",
    "# # Build clustering model using Affinity Propagation model\n",
    "# _, labels = cluster.affinity_propagation(edge_model.covariance_)\n",
    "# num_labels = labels.max()\n",
    "# num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the results of clustering\n",
    "# print('Clustering of stocks based on difference in opening and closing quotes:')\n",
    "# for i in range(num_labels + 1):\n",
    "#     print(\"Cluster\", i+1, \"==>\", ', '.join(names[labels == i]))\n",
    "#     # print(\"Cluster\", i+1, \"==>\", ', '.join(name_sample[labels == i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for quote in quotes:\n",
    "#     print(quote.loc[(quote.index > start_date) & (quote.index <= end_date)].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_stocks(quotes, labels, names, start_date, end_date):\n",
    "    quote_samples = [quote.loc[(quote.index > start_date) & (quote.index <= end_date)] for quote in quotes]\n",
    "    p1_label, p2_label = labels\n",
    "    p1_quotes = np.array([quote[p1_label] for quote in quote_samples]).astype(np.float)\n",
    "    p2_quotes = np.array([quote[p2_label] for quote in quote_samples]).astype(np.float)\n",
    "    quotes_diff = abs(p1_quotes - p2_quotes)\n",
    "    X = quotes_diff.copy().T\n",
    "    X /= X.std(axis=0)\n",
    "    edge_model = covariance.GraphicalLassoCV()\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        edge_model.fit(X)\n",
    "    _, labels = cluster.affinity_propagation(edge_model.covariance_)\n",
    "    num_labels = labels.max()\n",
    "    print(f'Clustering of stocks based on difference in {p1_label} and {p2_label} quotes:')\n",
    "    for i in range(num_labels + 1):\n",
    "        print(\"Cluster\", i+1, \"==>\", ', '.join(names[labels == i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering of stocks based on difference in Open and High quotes:\n",
      "Cluster 1 ==> Total, Exxon, Chevron, ConocoPhillips, Valero Energy, Microsoft, IBM, Time Warner, Comcast, Cablevision, Yahoo, Dell, HP, Amazon, Toyota, Canon, Mitsubishi, Sony, Ford, Honda, Navistar, Northrop Grumman\n",
      "Cluster 2 ==> American express, Walgreen, Home Depot, GlaxoSmithKline, Kimberly-Clark, Ryder, Caterpillar, DuPont de Nemours\n",
      "Cluster 3 ==> Boeing, Coca Cola, 3M, Mc Donalds, Pepsi, Kraft Foods, Kellogg, Unilever, Marriott, Procter Gamble, Colgate-Palmolive, General Electrics, Wells Fargo, JPMorgan Chase, AIG, Bank of America, Goldman Sachs, Apple, SAP, Cisco, Texas instruments, Xerox, Lookheed Martin, Wal-Mart, Pfizer, Sanofi-Aventis, Novartis, General Dynamics, Raytheon, CVS\n"
     ]
    }
   ],
   "source": [
    "start_date = '2007-01-01'\n",
    "end_date   = '2023-09-01'\n",
    "cluster_stocks(quotes, ['Open', 'High'], names, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering of stocks based on difference in Open and Close quotes:\n",
      "Cluster 1 ==> Total, Goldman Sachs, Apple, SAP\n",
      "Cluster 2 ==> Exxon, Chevron, ConocoPhillips, Valero Energy, Microsoft, Wells Fargo, JPMorgan Chase, AIG, American express, Bank of America\n",
      "Cluster 3 ==> Sony, Unilever, Marriott, Procter Gamble, Colgate-Palmolive, General Electrics, Cisco, Texas instruments, Xerox, Lookheed Martin, Wal-Mart, Walgreen, Home Depot, GlaxoSmithKline, Pfizer, Sanofi-Aventis, Novartis, Kimberly-Clark, Ryder, General Dynamics, Raytheon, CVS, Caterpillar, DuPont de Nemours\n",
      "Cluster 4 ==> IBM, Time Warner, Comcast, Cablevision, Yahoo, Dell, HP, Amazon, Toyota, Canon, Mitsubishi, Ford, Honda, Navistar, Northrop Grumman, Boeing, Coca Cola, 3M, Mc Donalds, Pepsi, Kraft Foods, Kellogg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hung/.local/share/virtualenvs/data-science-k2Ak_Bao/lib/python3.11/site-packages/sklearn/covariance/_graph_lasso.py:183: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: -1.216e-04\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "start_date = '2010-01-01'\n",
    "end_date   = '2023-09-01'\n",
    "cluster_stocks(quotes, ['Open', 'Close'], names, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering of stocks based on difference in Low and Close quotes:\n",
      "Cluster 1 ==> Total, Goldman Sachs, Apple, SAP\n",
      "Cluster 2 ==> Exxon, Chevron, ConocoPhillips, Valero Energy, Microsoft, Wells Fargo, JPMorgan Chase, AIG, American express, Bank of America\n",
      "Cluster 3 ==> Sony, Unilever, Marriott, Procter Gamble, Colgate-Palmolive, General Electrics, Cisco, Texas instruments, Xerox, Lookheed Martin, Wal-Mart, Walgreen, Home Depot, GlaxoSmithKline, Pfizer, Sanofi-Aventis, Novartis, Kimberly-Clark, Ryder, General Dynamics, Raytheon, CVS, Caterpillar, DuPont de Nemours\n",
      "Cluster 4 ==> IBM, Time Warner, Comcast, Cablevision, Yahoo, Dell, HP, Amazon, Toyota, Canon, Mitsubishi, Ford, Honda, Navistar, Northrop Grumman, Boeing, Coca Cola, 3M, Mc Donalds, Pepsi, Kraft Foods, Kellogg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hung/.local/share/virtualenvs/data-science-k2Ak_Bao/lib/python3.11/site-packages/sklearn/covariance/_graph_lasso.py:183: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: -1.216e-04\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "start_date_1 = '2018-01-01'\n",
    "end_date_1   = '2023-09-01'\n",
    "cluster_stocks(quotes, ['Low', 'Close'], names, start_date_1, end_date_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering of stocks based on difference in Low and High quotes:\n",
      "Cluster 1 ==> Total, ConocoPhillips, Valero Energy, Goldman Sachs, Novartis, Kimberly-Clark, Ryder, General Dynamics, Raytheon, CVS, Caterpillar, DuPont de Nemours\n",
      "Cluster 2 ==> Microsoft, IBM, Time Warner, Comcast, Cablevision, Yahoo, Dell, HP, Amazon, Toyota, Canon, Mitsubishi\n",
      "Cluster 3 ==> Exxon, Chevron, Sony, Ford, Honda, Navistar, Northrop Grumman, Boeing, Coca Cola\n",
      "Cluster 4 ==> 3M, Mc Donalds, Pepsi, Kraft Foods, Kellogg, Unilever, Marriott, Procter Gamble, Colgate-Palmolive, Bank of America, Apple, SAP, Cisco, Texas instruments, Xerox, Lookheed Martin, Wal-Mart, Walgreen\n",
      "Cluster 5 ==> General Electrics, Home Depot, GlaxoSmithKline, Pfizer\n",
      "Cluster 6 ==> Wells Fargo, JPMorgan Chase, AIG, American express, Sanofi-Aventis\n"
     ]
    }
   ],
   "source": [
    "start_date_1 = '2006-01-01'\n",
    "end_date_1   = '2023-09-01'\n",
    "cluster_stocks(quotes, ['Low', 'High'], names, start_date_1, end_date_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science-k2Ak_Bao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
